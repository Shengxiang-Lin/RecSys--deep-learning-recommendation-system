{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Multi-Interest Network with Dynamic Routing (MIMD)","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport zipfile\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\n# 胶囊网络层\nclass CapsuleLayer(nn.Module):\n    \"\"\"胶囊网络层，实现B2I动态路由算法\"\"\"\n    def __init__(self, input_units, out_units, max_len, k_max=4, iterations=3):\n        super(CapsuleLayer, self).__init__()\n        self.input_units = input_units\n        self.out_units = out_units\n        self.max_len = max_len\n        self.k_max = k_max\n        self.iterations = iterations\n        self.shared_weights = nn.Parameter(torch.randn(1, input_units, out_units))\n        \n    def forward(self, inputs):\n        history_emb, hist_len = inputs\n        batch_size = history_emb.size(0)\n        k_user = torch.clamp(torch.floor(torch.log2(hist_len.float())), min=1, max=self.k_max).long()\n        b_ij = torch.randn(batch_size, self.max_len, self.k_max, device=history_emb.device)\n        for i in range(self.iterations):\n            c_ij = F.softmax(b_ij, dim=2)\n            mask = torch.arange(self.max_len, device=hist_len.device).expand(batch_size, self.max_len) >= hist_len.unsqueeze(1)\n            c_ij = c_ij.masked_fill(mask.unsqueeze(2), 0)\n            u_hat = torch.matmul(history_emb, self.shared_weights)\n            s_j = torch.bmm(c_ij.transpose(1, 2), u_hat)\n            v_j = self.squash(s_j)\n            if i < self.iterations - 1:\n                u_v = torch.bmm(u_hat, v_j.transpose(1, 2))\n                b_ij = b_ij + u_v\n        final_v_j = []\n        for i in range(batch_size):\n            final_v_j.append(v_j[i, :k_user[i], :])\n        max_k = k_user.max().item()\n        output = torch.zeros(batch_size, max_k, self.out_units, device=history_emb.device)\n        for i in range(batch_size):\n            output[i, :k_user[i], :] = final_v_j[i]\n        return output, k_user\n    \n    def squash(self, inputs):\n        norm = torch.norm(inputs, p=2, dim=2, keepdim=True)\n        norm_squared = norm ** 2\n        scale = norm_squared / (1 + norm_squared) / (norm + 1e-8)\n        return scale * inputs\n\n# 标签感知注意力层\nclass LabelAwareAttention(nn.Module):\n    \"\"\"标签感知注意力层，根据目标物品调整用户的多兴趣表示\"\"\"\n    def __init__(self, embedding_dim, k_max=4, pow_p=1.0, dynamic_k=False):\n        super(LabelAwareAttention, self).__init__()\n        self.embedding_dim = embedding_dim\n        self.k_max = k_max\n        self.pow_p = pow_p\n        self.dynamic_k = dynamic_k\n        self.attention = nn.Sequential(\n            nn.Linear(embedding_dim * 2, embedding_dim),\n            nn.Tanh(),\n            nn.Linear(embedding_dim, 1)\n        )\n    \n    def forward(self, inputs):\n        if self.dynamic_k and len(inputs) == 3:\n            user_embeddings, target_embedding, k_user = inputs\n        else:\n            user_embeddings, target_embedding = inputs\n            k_user = torch.full((user_embeddings.size(0),), self.k_max, dtype=torch.long, device=user_embeddings.device)\n        batch_max_k = k_user.max().item()\n        batch_size = user_embeddings.size(0)\n        processed_user_embeddings = torch.zeros(batch_size, batch_max_k, self.embedding_dim, device=user_embeddings.device)\n        for i in range(batch_size):\n            actual_k = k_user[i].item()\n            user_interest = user_embeddings[i, :actual_k, :]\n            if actual_k > batch_max_k:\n                processed_user_embeddings[i] = user_interest[:batch_max_k]\n            else:\n                processed_user_embeddings[i, :actual_k] = user_interest[:batch_max_k]\n        target_embedding = target_embedding.expand(-1, batch_max_k, -1)\n        concat_vector = torch.cat([processed_user_embeddings, target_embedding], dim=2)\n        similarity = self.attention(concat_vector).squeeze(2)\n        mask = torch.arange(batch_max_k, device=user_embeddings.device).expand(batch_size, batch_max_k) >= k_user.unsqueeze(1)\n        similarity = similarity.masked_fill(mask, -1e9)\n        if self.pow_p != 1.0:\n            similarity = torch.pow(similarity, self.pow_p)\n        \n        attention_weights = F.softmax(similarity, dim=1).unsqueeze(2)\n        user_embedding = torch.sum(processed_user_embeddings * attention_weights, dim=1)\n        return user_embedding\n\n# MIND模型\nclass MIND(nn.Module):\n    \"\"\"Multi-Interest Network with Dynamic Routing模型\"\"\"\n    def __init__(self, item_count, embedding_dim=64, k_max=4, pow_p=1.0, dynamic_k=True):\n        super(MIND, self).__init__()\n        self.item_count = item_count\n        self.embedding_dim = embedding_dim\n        self.k_max = k_max\n        self.pow_p = pow_p\n        self.dynamic_k = dynamic_k\n        self.item_embedding = nn.Embedding(item_count, embedding_dim, padding_idx=0)\n        self.capsule_layer = CapsuleLayer(embedding_dim, embedding_dim, max_len=50, k_max=k_max)\n        self.label_aware_attention = LabelAwareAttention(embedding_dim, k_max=k_max, pow_p=pow_p, dynamic_k=dynamic_k)\n        \n    def forward(self, user_hist, target_item=None, hist_len=None):\n        hist_emb = self.item_embedding(user_hist)\n        multi_interests, k_user = self.capsule_layer((hist_emb, hist_len))\n        if target_item is not None:\n            target_emb = self.item_embedding(target_item).unsqueeze(1)\n            if self.dynamic_k:\n                user_embedding = self.label_aware_attention((multi_interests, target_emb, k_user))\n            else:\n                user_embedding = self.label_aware_attention((multi_interests, target_emb))\n            return user_embedding, multi_interests\n        else:\n            return multi_interests\n    \n    def calculate_loss(self, user_embedding, target_item):\n        all_item_emb = self.item_embedding.weight\n        scores = torch.matmul(user_embedding, all_item_emb.transpose(0, 1))\n        loss = F.cross_entropy(scores, target_item)\n        return loss\n\n# 数据集类\nclass UserItemDataset(Dataset):\n    def __init__(self, user_hists, target_items, hist_lens):\n        self.user_hists = user_hists\n        self.target_items = target_items\n        self.hist_lens = hist_lens\n        \n    def __len__(self):\n        return len(self.user_hists)\n    \n    def __getitem__(self, idx):\n        return {\n            'user_hist': torch.tensor(self.user_hists[idx], dtype=torch.long),\n            'target_item': torch.tensor(self.target_items[idx], dtype=torch.long),\n            'hist_len': torch.tensor(self.hist_lens[idx], dtype=torch.long)\n        }\n\n# 下载并处理MovieLens数据集\ndef download_and_preprocess_movielens():\n    # 如果数据集不存在，则下载\n    data_path = 'ml-1m'\n    zip_path = 'ml-1m.zip'\n    ratings_file = os.path.join(data_path, 'ratings.dat')\n    if not os.path.exists(data_path):\n        if not os.path.exists(zip_path):\n            print(\"下载MovieLens-1M数据集...\")\n            import requests\n            url = 'https://files.grouplens.org/datasets/movielens/ml-1m.zip'\n            r = requests.get(url)\n            with open(zip_path, 'wb') as f:\n                f.write(r.content)\n        print(\"解压数据集...\")\n        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n            zip_ref.extractall('.')\n    print(\"读取和处理数据...\")\n    ratings = pd.read_csv(ratings_file, sep='::', \n                         engine='python', \n                         names=['user_id', 'movie_id', 'rating', 'timestamp'])\n    # 过滤低评分\n    ratings = ratings[ratings['rating'] >= 4]  # 只保留评分4分及以上的\n    # 按用户分组并按时间排序\n    ratings.sort_values(['user_id', 'timestamp'], inplace=True)\n    # 构建用户历史序列\n    user_sequences = ratings.groupby('user_id')['movie_id'].apply(list).reset_index()\n    user_sequences.columns = ['user_id', 'movie_list']\n    # 添加序列长度\n    user_sequences['hist_len'] = user_sequences['movie_list'].apply(len)\n    # 过滤序列长度太短的用户\n    user_sequences = user_sequences[user_sequences['hist_len'] >= 5]\n    # 分割每个用户的序列为历史序列和目标\n    def split_sequence(row):\n        seq = row['movie_list']\n        # 最后两个物品分别作为验证和测试的目标\n        return seq[:-2], seq[-2], seq[-1]\n    user_sequences[['hist', 'val_target', 'test_target']] = user_sequences.apply(\n        lambda row: split_sequence(row), axis=1, result_type='expand')\n    # 创建训练集、验证集和测试集\n    train_data = user_sequences[['hist', 'val_target', 'hist_len']].copy()\n    train_data.rename(columns={'val_target': 'target'}, inplace=True)\n    val_data = user_sequences[['hist', 'test_target', 'hist_len']].copy()\n    val_data.rename(columns={'test_target': 'target'}, inplace=True)\n    # 创建测试集：使用整个序列的最后一部分作为目标\n    test_data = user_sequences[['movie_list', 'test_target', 'hist_len']].copy()\n    test_data.rename(columns={'movie_list': 'hist', 'test_target': 'target'}, inplace=True)\n    # 获取物品数量\n    num_items = ratings['movie_id'].max() + 1  # +1 因为ID从1开始\n    # 填充序列到固定长度\n    max_len = 50\n    def pad_sequences(sequences, max_len, pad_value=0):\n        padded = []\n        for seq in sequences:\n            if len(seq) < max_len:\n                padded.append(seq + [pad_value] * (max_len - len(seq)))\n            else:\n                padded.append(seq[:max_len])\n        return padded\n    train_user_hists = pad_sequences(train_data['hist'].tolist(), max_len)\n    train_target_items = train_data['target'].tolist()\n    train_hist_lens = [min(l, max_len) for l in train_data['hist_len']]\n    val_user_hists = pad_sequences(val_data['hist'].tolist(), max_len)\n    val_target_items = val_data['target'].tolist()\n    val_hist_lens = [min(l, max_len) for l in val_data['hist_len']]\n    test_user_hists = pad_sequences(test_data['hist'].tolist(), max_len)\n    test_target_items = test_data['target'].tolist()\n    test_hist_lens = [min(l, max_len) for l in test_data['hist_len']]\n    return (train_user_hists, train_target_items, train_hist_lens,\n            val_user_hists, val_target_items, val_hist_lens,\n            test_user_hists, test_target_items, test_hist_lens,\n            num_items)\n\n# 训练函数\ndef train_model(model, train_loader, val_loader, optimizer, scheduler, device, epochs=10):\n    train_losses = []\n    val_losses = []\n    metrics_history = {\n        'HR@10': [], 'HR@20': [], 'HR@50': [],\n        'NDCG@10': [], 'NDCG@20': [], 'NDCG@50': []\n    }\n    best_val_loss = float('inf')\n    for epoch in range(epochs):\n        # 训练阶段\n        model.train()\n        total_train_loss = 0\n        #for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]'):\n        for batch in train_loader:\n            user_hist = batch['user_hist'].to(device)\n            target_item = batch['target_item'].to(device)\n            hist_len = batch['hist_len'].to(device)\n            optimizer.zero_grad()\n            user_embedding, _ = model(user_hist, target_item, hist_len)\n            loss = model.calculate_loss(user_embedding, target_item)\n            loss.backward()\n            optimizer.step()\n            total_train_loss += loss.item()\n        avg_train_loss = total_train_loss / len(train_loader)\n        train_losses.append(avg_train_loss)\n        # 验证阶段\n        model.eval()\n        total_val_loss = 0\n        with torch.no_grad():\n            #for batch in tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]'):\n            for batch in val_loader:\n                user_hist = batch['user_hist'].to(device)\n                target_item = batch['target_item'].to(device)\n                hist_len = batch['hist_len'].to(device) \n                user_embedding, _ = model(user_hist, target_item, hist_len)\n                loss = model.calculate_loss(user_embedding, target_item)\n                total_val_loss += loss.item()\n        avg_val_loss = total_val_loss / len(val_loader)\n        val_losses.append(avg_val_loss)\n        # 更新学习率\n        scheduler.step(avg_val_loss)\n        if (epoch + 1) % 10 == 0 or epoch == epochs - 1:\n            print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n            print(f\"Evaluating model at epoch {epoch+1}...\")\n            metrics = evaluate_model(model, val_loader, device)\n            for key, value in metrics.items():\n                metrics_history[key].append(value)\n        # 保存最佳模型\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            torch.save(model.state_dict(), 'best_mind_model.pth')\n    return train_losses, val_losses, metrics_history\n\n# 评估函数\ndef evaluate_model(model, data_loader, device, top_k_list=[10, 20, 50]):\n    model.eval()\n    metrics = {f'HR@{k}': [] for k in top_k_list}\n    metrics.update({f'NDCG@{k}': [] for k in top_k_list})\n    with torch.no_grad():\n        #for batch in tqdm(data_loader, desc='Evaluating'):\n        for batch in data_loader:\n            user_hist = batch['user_hist'].to(device)\n            target_item = batch['target_item'].to(device)\n            hist_len = batch['hist_len'].to(device)\n            multi_interests = model(user_hist, None, hist_len)\n            all_item_emb = model.item_embedding.weight\n            # 计算相似度\n            similarities = torch.bmm(multi_interests, all_item_emb.transpose(0, 1).unsqueeze(0).expand(multi_interests.size(0), -1, -1))\n            max_similarities, _ = torch.max(similarities, dim=1)\n            # 排除历史行为中的物品\n            for i in range(user_hist.size(0)):\n                hist_items = user_hist[i][:hist_len[i]]\n                max_similarities[i, hist_items] = -float('inf')\n            # 计算指标\n            for k in top_k_list:\n                _, top_indices = torch.topk(max_similarities, k=k, dim=1)\n                for i in range(user_hist.size(0)):\n                    if target_item[i] in top_indices[i]:\n                        metrics[f'HR@{k}'].append(1)\n                        rank = (top_indices[i] == target_item[i]).nonzero(as_tuple=True)[0][0].item() + 1\n                        metrics[f'NDCG@{k}'].append(1 / math.log2(rank + 1))\n                    else:\n                        metrics[f'HR@{k}'].append(0)\n                        metrics[f'NDCG@{k}'].append(0)\n    # 打印指标\n    for k in top_k_list:\n        hr = np.mean(metrics[f'HR@{k}'])\n        ndcg = np.mean(metrics[f'NDCG@{k}'])\n        print(f'HR@{k}: {hr:.4f}, NDCG@{k}: {ndcg:.4f}')\n    return {key: np.mean(values) for key, values in metrics.items()}\n\n# 主函数\ndef main():\n    # 设置参数\n    embedding_dim = 64\n    k_max = 5\n    pow_p = 1.0\n    dynamic_k = True\n    batch_size = 256\n    epochs = 1000\n    learning_rate = 0.001\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(\"下载并处理MovieLens-1M数据集...\")\n    (train_user_hists, train_target_items, train_hist_lens,\n     val_user_hists, val_target_items, val_hist_lens,\n     test_user_hists, test_target_items, test_hist_lens,\n     num_items) = download_and_preprocess_movielens()\n    print(f\"数据集信息: 物品数量={num_items}, 训练样本={len(train_user_hists)}, \"\n          f\"验证样本={len(val_user_hists)}, 测试样本={len(test_user_hists)}\")\n    # 创建数据加载器\n    train_dataset = UserItemDataset(train_user_hists, train_target_items, train_hist_lens)\n    val_dataset = UserItemDataset(val_user_hists, val_target_items, val_hist_lens)\n    test_dataset = UserItemDataset(test_user_hists, test_target_items, test_hist_lens)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n    # 初始化模型\n    model = MIND(num_items, embedding_dim, k_max, pow_p, dynamic_k).to(device)\n    # 定义优化器和学习率调度器\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='min', factor=0.9, patience=3, verbose=True)\n    # 训练模型\n    print(\"开始训练模型...\")\n    train_losses, val_losses, metrics_history = train_model(\n        model, train_loader, val_loader, optimizer, scheduler, device, epochs)\n    # 加载最佳模型并在测试集上评估\n    model.load_state_dict(torch.load('best_mind_model.pth'))\n    print(\"评估测试集性能...\")\n    evaluate_model(model, test_loader, device)\n    print(\"训练和评估完成!\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T12:54:51.955024Z","iopub.execute_input":"2025-07-08T12:54:51.955639Z","execution_failed":"2025-07-08T13:46:00.510Z"}},"outputs":[{"name":"stdout","text":"下载并处理MovieLens-1M数据集...\n读取和处理数据...\n数据集信息: 物品数量=3953, 训练样本=6034, 验证样本=6034, 测试样本=6034\n开始训练模型...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/1000, Train Loss: 8.1761, Val Loss: 8.2133, LR: 0.001000\nEvaluating model at epoch 10...\nHR@10: 0.0028, NDCG@10: 0.0014\nHR@20: 0.0053, NDCG@20: 0.0020\nHR@50: 0.0157, NDCG@50: 0.0040\nEpoch 20/1000, Train Loss: 7.6391, Val Loss: 7.7482, LR: 0.001000\nEvaluating model at epoch 20...\nHR@10: 0.0027, NDCG@10: 0.0012\nHR@20: 0.0056, NDCG@20: 0.0020\nHR@50: 0.0134, NDCG@50: 0.0035\nEpoch 30/1000, Train Loss: 7.3126, Val Loss: 7.4985, LR: 0.001000\nEvaluating model at epoch 30...\nHR@10: 0.0073, NDCG@10: 0.0029\nHR@20: 0.0141, NDCG@20: 0.0046\nHR@50: 0.0282, NDCG@50: 0.0074\nEpoch 40/1000, Train Loss: 7.0913, Val Loss: 7.3245, LR: 0.001000\nEvaluating model at epoch 40...\nHR@10: 0.0114, NDCG@10: 0.0063\nHR@20: 0.0169, NDCG@20: 0.0077\nHR@50: 0.0348, NDCG@50: 0.0112\nEpoch 50/1000, Train Loss: 6.9295, Val Loss: 7.2140, LR: 0.001000\nEvaluating model at epoch 50...\nHR@10: 0.0172, NDCG@10: 0.0096\nHR@20: 0.0267, NDCG@20: 0.0120\nHR@50: 0.0479, NDCG@50: 0.0161\nEpoch 60/1000, Train Loss: 6.7960, Val Loss: 7.1227, LR: 0.001000\nEvaluating model at epoch 60...\nHR@10: 0.0220, NDCG@10: 0.0120\nHR@20: 0.0308, NDCG@20: 0.0142\nHR@50: 0.0608, NDCG@50: 0.0201\nEpoch 70/1000, Train Loss: 6.6725, Val Loss: 7.0497, LR: 0.001000\nEvaluating model at epoch 70...\nHR@10: 0.0232, NDCG@10: 0.0120\nHR@20: 0.0376, NDCG@20: 0.0157\nHR@50: 0.0703, NDCG@50: 0.0221\nEpoch 80/1000, Train Loss: 6.5766, Val Loss: 6.9838, LR: 0.001000\nEvaluating model at epoch 80...\nHR@10: 0.0287, NDCG@10: 0.0158\nHR@20: 0.0452, NDCG@20: 0.0200\nHR@50: 0.0812, NDCG@50: 0.0270\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport zipfile\nimport requests\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\n# 胶囊网络层\nclass CapsuleLayer(nn.Module):\n    \"\"\"胶囊网络层，实现B2I动态路由算法\"\"\"\n    def __init__(self, input_units, out_units, max_len, k_max=4, iterations=3):\n        super(CapsuleLayer, self).__init__()\n        self.input_units = input_units\n        self.out_units = out_units\n        self.max_len = max_len\n        self.k_max = k_max\n        self.iterations = iterations\n        self.shared_weights = nn.Parameter(torch.randn(1, input_units, out_units))\n        \n    def forward(self, inputs):\n        history_emb, hist_len = inputs\n        batch_size = history_emb.size(0)\n        k_user = torch.clamp(torch.floor(torch.log2(hist_len.float())), min=1, max=self.k_max).long()\n        b_ij = torch.randn(batch_size, self.max_len, self.k_max, device=history_emb.device)\n        for i in range(self.iterations):\n            c_ij = F.softmax(b_ij, dim=2)\n            mask = torch.arange(self.max_len, device=hist_len.device).expand(batch_size, self.max_len) >= hist_len.unsqueeze(1)\n            c_ij = c_ij.masked_fill(mask.unsqueeze(2), 0)\n            u_hat = torch.matmul(history_emb, self.shared_weights)\n            s_j = torch.bmm(c_ij.transpose(1, 2), u_hat)\n            v_j = self.squash(s_j)\n            if i < self.iterations - 1:\n                u_v = torch.bmm(u_hat, v_j.transpose(1, 2))\n                b_ij = b_ij + u_v\n        \n        final_v_j = []\n        for i in range(batch_size):\n            final_v_j.append(v_j[i, :k_user[i], :])\n        max_k = k_user.max().item()\n        output = torch.zeros(batch_size, max_k, self.out_units, device=history_emb.device)\n        for i in range(batch_size):\n            output[i, :k_user[i], :] = final_v_j[i]\n        return output, k_user\n    \n    def squash(self, inputs):\n        norm = torch.norm(inputs, p=2, dim=2, keepdim=True)\n        norm_squared = norm ** 2\n        scale = norm_squared / (1 + norm_squared) / (norm + 1e-8)\n        return scale * inputs\n\n# 标签感知注意力层\nclass LabelAwareAttention(nn.Module):\n    \"\"\"标签感知注意力层，根据目标物品调整用户的多兴趣表示\"\"\"\n    def __init__(self, embedding_dim, k_max=4, pow_p=1.0, dynamic_k=False):\n        super(LabelAwareAttention, self).__init__()\n        self.embedding_dim = embedding_dim\n        self.k_max = k_max\n        self.pow_p = pow_p\n        self.dynamic_k = dynamic_k\n        self.attention = nn.Sequential(\n            nn.Linear(embedding_dim * 2, embedding_dim),\n            nn.Tanh(),\n            nn.Linear(embedding_dim, 1)\n        )\n    \n    def forward(self, inputs):\n        if self.dynamic_k and len(inputs) == 3:\n            user_embeddings, target_embedding, k_user = inputs\n        else:\n            user_embeddings, target_embedding = inputs\n            k_user = torch.full((user_embeddings.size(0),), self.k_max, dtype=torch.long, device=user_embeddings.device)\n        batch_max_k = k_user.max().item()\n        batch_size = user_embeddings.size(0)\n        processed_user_embeddings = torch.zeros(batch_size, batch_max_k, self.embedding_dim, device=user_embeddings.device)\n        for i in range(batch_size):\n            actual_k = k_user[i].item()\n            user_interest = user_embeddings[i, :actual_k, :]\n            if actual_k > batch_max_k:\n                processed_user_embeddings[i] = user_interest[:batch_max_k]\n            else:\n                processed_user_embeddings[i, :actual_k] = user_interest[:batch_max_k]\n        target_embedding = target_embedding.expand(-1, batch_max_k, -1)\n        concat_vector = torch.cat([processed_user_embeddings, target_embedding], dim=2)\n        similarity = self.attention(concat_vector).squeeze(2)\n        mask = torch.arange(batch_max_k, device=user_embeddings.device).expand(batch_size, batch_max_k) >= k_user.unsqueeze(1)\n        similarity = similarity.masked_fill(mask, -1e9)\n        if self.pow_p != 1.0:\n            similarity = torch.pow(similarity, self.pow_p)\n        attention_weights = F.softmax(similarity, dim=1).unsqueeze(2)\n        user_embedding = torch.sum(processed_user_embeddings * attention_weights, dim=1)\n        return user_embedding\n\n# MIND模型\nclass MIND(nn.Module):\n    \"\"\"Multi-Interest Network with Dynamic Routing模型\"\"\"\n    def __init__(self, item_count, embedding_dim=64, k_max=4, pow_p=1.0, dynamic_k=True):\n        super(MIND, self).__init__()\n        self.item_count = item_count\n        self.embedding_dim = embedding_dim\n        self.k_max = k_max\n        self.pow_p = pow_p\n        self.dynamic_k = dynamic_k\n        self.item_embedding = nn.Embedding(item_count, embedding_dim, padding_idx=0)\n        self.capsule_layer = CapsuleLayer(embedding_dim, embedding_dim, max_len=50, k_max=k_max)\n        self.label_aware_attention = LabelAwareAttention(embedding_dim, k_max=k_max, pow_p=pow_p, dynamic_k=dynamic_k)\n        \n    def forward(self, user_hist, target_item=None, hist_len=None):\n        hist_emb = self.item_embedding(user_hist)\n        multi_interests, k_user = self.capsule_layer((hist_emb, hist_len))\n        if target_item is not None:\n            target_emb = self.item_embedding(target_item).unsqueeze(1)\n            if self.dynamic_k:\n                user_embedding = self.label_aware_attention((multi_interests, target_emb, k_user))\n            else:\n                user_embedding = self.label_aware_attention((multi_interests, target_emb))\n            return user_embedding, multi_interests\n        else:\n            return multi_interests\n    \n    def calculate_loss(self, user_embedding, target_item):\n        all_item_emb = self.item_embedding.weight\n        scores = torch.matmul(user_embedding, all_item_emb.transpose(0, 1))\n        loss = F.cross_entropy(scores, target_item)\n        return loss\n\n# 数据集类\nclass UserItemDataset(Dataset):\n    def __init__(self, user_hists, target_items, hist_lens):\n        self.user_hists = user_hists\n        self.target_items = target_items\n        self.hist_lens = hist_lens\n        \n    def __len__(self):\n        return len(self.user_hists)\n    \n    def __getitem__(self, idx):\n        return {\n            'user_hist': torch.tensor(self.user_hists[idx], dtype=torch.long),\n            'target_item': torch.tensor(self.target_items[idx], dtype=torch.long),\n            'hist_len': torch.tensor(self.hist_lens[idx], dtype=torch.long)\n        }\n\n# 下载并处理MovieLens数据集\ndef download_and_preprocess_movielens():\n    # 如果数据集不存在，则下载\n    data_path = 'ml-1m'\n    zip_path = 'ml-1m.zip'\n    ratings_file = os.path.join(data_path, 'ratings.dat')\n    if not os.path.exists(data_path):\n        if not os.path.exists(zip_path):\n            print(\"下载MovieLens-1M数据集...\")\n            url = 'https://files.grouplens.org/datasets/movielens/ml-1m.zip'\n            r = requests.get(url)\n            with open(zip_path, 'wb') as f:\n                f.write(r.content)\n        print(\"解压数据集...\")\n        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n            zip_ref.extractall('.')\n    print(\"读取和处理数据...\")\n    ratings = pd.read_csv(ratings_file, sep='::', \n                         engine='python', \n                         names=['user_id', 'movie_id', 'rating', 'timestamp'])\n    # 过滤低评分\n    ratings = ratings[ratings['rating'] >= 4]  # 只保留评分4分及以上的\n    \n    # 按用户分组并按时间排序\n    ratings.sort_values(['user_id', 'timestamp'], inplace=True)\n    # 构建用户历史序列\n    user_sequences = ratings.groupby('user_id')['movie_id'].apply(list).reset_index()\n    user_sequences.columns = ['user_id', 'movie_list']\n    # 添加序列长度\n    user_sequences['hist_len'] = user_sequences['movie_list'].apply(len)\n    # 过滤序列长度太短的用户\n    user_sequences = user_sequences[user_sequences['hist_len'] >= 5]\n    # 分割每个用户的序列为历史序列和目标\n    def split_sequence(row):\n        seq = row['movie_list']\n        # 最后两个物品分别作为验证和测试的目标\n        return seq[:-2], seq[-2], seq[-1]\n    user_sequences[['hist', 'val_target', 'test_target']] = user_sequences.apply(\n        lambda row: split_sequence(row), axis=1, result_type='expand')\n    # 创建训练集、验证集和测试集\n    train_data = user_sequences[['hist', 'val_target', 'hist_len']].copy()\n    train_data.rename(columns={'val_target': 'target'}, inplace=True)\n    val_data = user_sequences[['hist', 'test_target', 'hist_len']].copy()\n    val_data.rename(columns={'test_target': 'target'}, inplace=True)\n    # 创建测试集：使用整个序列的最后一部分作为目标\n    test_data = user_sequences[['movie_list', 'test_target', 'hist_len']].copy()\n    test_data.rename(columns={'movie_list': 'hist', 'test_target': 'target'}, inplace=True)\n    # 获取物品数量\n    num_items = ratings['movie_id'].max() + 1  # +1 因为ID从1开始\n    # 填充序列到固定长度\n    max_len = 50\n    def pad_sequences(sequences, max_len, pad_value=0):\n        padded = []\n        for seq in sequences:\n            if len(seq) < max_len:\n                padded.append(seq + [pad_value] * (max_len - len(seq)))\n            else:\n                padded.append(seq[:max_len])\n        return padded\n    train_user_hists = pad_sequences(train_data['hist'].tolist(), max_len)\n    train_target_items = train_data['target'].tolist()\n    train_hist_lens = [min(l, max_len) for l in train_data['hist_len']]\n    val_user_hists = pad_sequences(val_data['hist'].tolist(), max_len)\n    val_target_items = val_data['target'].tolist()\n    val_hist_lens = [min(l, max_len) for l in val_data['hist_len']]\n    test_user_hists = pad_sequences(test_data['hist'].tolist(), max_len)\n    test_target_items = test_data['target'].tolist()\n    test_hist_lens = [min(l, max_len) for l in test_data['hist_len']]\n    return (train_user_hists, train_target_items, train_hist_lens,\n            val_user_hists, val_target_items, val_hist_lens,\n            test_user_hists, test_target_items, test_hist_lens,\n            num_items)\n\n# 训练函数\ndef train_model(model, train_loader, val_loader, optimizer, scheduler, device, epochs=10):\n    train_losses = []\n    val_losses = []\n    metrics_history = {\n        'HR@10': [], 'HR@20': [], 'HR@50': [],\n        'NDCG@10': [], 'NDCG@20': [], 'NDCG@50': []\n    }\n    best_val_loss = float('inf')\n    best_metrics = None\n    for epoch in range(epochs):\n        # 训练阶段\n        model.train()\n        total_train_loss = 0\n        #for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]'):\n        for batch in train_loader:\n            user_hist = batch['user_hist'].to(device)\n            target_item = batch['target_item'].to(device)\n            hist_len = batch['hist_len'].to(device)\n            optimizer.zero_grad()\n            user_embedding, _ = model(user_hist, target_item, hist_len)\n            loss = model.calculate_loss(user_embedding, target_item)\n            loss.backward()\n            optimizer.step()\n            total_train_loss += loss.item()\n        \n        avg_train_loss = total_train_loss / len(train_loader)\n        train_losses.append(avg_train_loss)\n        # 验证阶段\n        model.eval()\n        total_val_loss = 0\n        with torch.no_grad():\n            #for batch in tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]'):\n            for batch in val_loader:\n                user_hist = batch['user_hist'].to(device)\n                target_item = batch['target_item'].to(device)\n                hist_len = batch['hist_len'].to(device)\n                user_embedding, _ = model(user_hist, target_item, hist_len)\n                loss = model.calculate_loss(user_embedding, target_item)\n                total_val_loss += loss.item()\n        \n        avg_val_loss = total_val_loss / len(val_loader)\n        val_losses.append(avg_val_loss)\n        # 更新学习率\n        scheduler.step(avg_val_loss)\n        # 每10个epoch评估一次模型\n        if (epoch + 1) % 10 == 0 or epoch == epochs - 1:\n            print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n            print(f\"Evaluating model at epoch {epoch+1}...\")\n            metrics = evaluate_model(model, val_loader, device)\n            for key, value in metrics.items():\n                metrics_history[key].append(value)  \n            # 保存最佳指标\n            if best_metrics is None or metrics['HR@10'] > best_metrics['HR@10']:\n                 best_metrics = metrics\n        # 保存最佳模型\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            torch.save(model.state_dict(), 'best_mind_model.pth')\n    return train_losses, val_losses, metrics_history, best_metrics\n\n# 评估函数\ndef evaluate_model(model, data_loader, device, top_k_list=[10, 20, 50]):\n    model.eval()\n    metrics = {f'HR@{k}': [] for k in top_k_list}\n    metrics.update({f'NDCG@{k}': [] for k in top_k_list})\n    \n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc='Evaluating'):\n            user_hist = batch['user_hist'].to(device)\n            target_item = batch['target_item'].to(device)\n            hist_len = batch['hist_len'].to(device)\n            multi_interests = model(user_hist, None, hist_len)\n            all_item_emb = model.item_embedding.weight\n            # 计算相似度\n            similarities = torch.bmm(multi_interests, all_item_emb.transpose(0, 1).unsqueeze(0).expand(multi_interests.size(0), -1, -1))\n            max_similarities, _ = torch.max(similarities, dim=1)\n            # 排除历史行为中的物品\n            for i in range(user_hist.size(0)):\n                hist_items = user_hist[i][:hist_len[i]]\n                max_similarities[i, hist_items] = -float('inf')\n            # 计算指标\n            for k in top_k_list:\n                _, top_indices = torch.topk(max_similarities, k=k, dim=1)\n                for i in range(user_hist.size(0)):\n                    if target_item[i] in top_indices[i]:\n                        metrics[f'HR@{k}'].append(1)\n                        rank = (top_indices[i] == target_item[i]).nonzero(as_tuple=True)[0][0].item() + 1\n                        metrics[f'NDCG@{k}'].append(1 / math.log2(rank + 1))\n                    else:\n                        metrics[f'HR@{k}'].append(0)\n                        metrics[f'NDCG@{k}'].append(0)\n    # 计算平均指标\n    avg_metrics = {}\n    for k in top_k_list:\n        hr = np.mean(metrics[f'HR@{k}'])\n        ndcg = np.mean(metrics[f'NDCG@{k}'])\n        avg_metrics[f'HR@{k}'] = hr\n        avg_metrics[f'NDCG@{k}'] = ndcg\n        print(f'HR@{k}: {hr:.4f}, NDCG@{k}: {ndcg:.4f}')\n    \n    return avg_metrics\n\n# 绘制损失曲线\ndef plot_losses(train_losses, val_losses, save_path='loss_curve.png'):\n    plt.figure(figsize=(10, 6))\n    plt.plot(train_losses, 'b-', label='Training Loss')\n    plt.plot(val_losses, 'r-', label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training and Validation Loss')\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(save_path)\n    plt.show()\n\n# 绘制指标曲线\ndef plot_metrics(metrics_history, epochs, save_path='metrics_curve.png'):\n    eval_epochs = [5 * (i+1) for i in range(len(metrics_history['HR@10']))]\n    plt.figure(figsize=(15, 10))\n    # 绘制HR指标对比\n    plt.subplot(2, 1, 1)\n    for k in [10, 20, 50]:\n        plt.plot(eval_epochs, metrics_history[f'HR@{k}'], 'o-', label=f'HR@{k}')\n    plt.xlabel('Epoch')\n    plt.ylabel('Hit Rate (HR)')\n    plt.title('Hit Rate at Different K Values')\n    plt.legend()\n    plt.grid(True)\n    # 绘制NDCG指标\n    plt.subplot(2, 1, 2)\n    for k in [10, 20, 50]:\n        plt.plot(eval_epochs, metrics_history[f'NDCG@{k}'], 'o-', label=f'NDCG@{k}')\n    plt.xlabel('Epoch')\n    plt.ylabel('Normalized Discounted Cumulative Gain (NDCG)')\n    plt.title('NDCG at Different K Values')\n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.show()\n\n# 绘制不同K值的最终指标对比\ndef plot_final_metrics(metrics, save_path='final_metrics.png'):\n    k_values = [10, 20, 50]\n    hr_values = [metrics[f'HR@{k}'] for k in k_values]\n    ndcg_values = [metrics[f'NDCG@{k}'] for k in k_values]\n    plt.figure(figsize=(12, 6))\n    # 绘制HR指标对比\n    plt.subplot(1, 2, 1)\n    plt.bar([str(k) for k in k_values], hr_values, color='skyblue')\n    plt.xlabel('K Value')\n    plt.ylabel('Hit Rate (HR)')\n    plt.title('HR at Different K Values')\n    plt.ylim(0, max(hr_values) * 1.2)\n    # 绘制NDCG指标对比\n    plt.subplot(1, 2, 2)\n    plt.bar([str(k) for k in k_values], ndcg_values, color='lightgreen')\n    plt.xlabel('K Value')\n    plt.ylabel('Normalized Discounted Cumulative Gain (NDCG)')\n    plt.title('NDCG at Different K Values')\n    plt.ylim(0, max(ndcg_values) * 1.2)\n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.show()\n\n# 主函数\ndef main():\n    # 设置参数\n    embedding_dim = 64\n    k_max = 5\n    pow_p = 1.0\n    dynamic_k = True\n    batch_size = 256\n    epochs = 1000\n    learning_rate = 0.01\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(\"下载并处理MovieLens-1M数据集...\")\n    (train_user_hists, train_target_items, train_hist_lens,\n     val_user_hists, val_target_items, val_hist_lens,\n     test_user_hists, test_target_items, test_hist_lens,\n     num_items) = download_and_preprocess_movielens()\n    print(f\"数据集信息: 物品数量={num_items}, 训练样本={len(train_user_hists)}, \"\n          f\"验证样本={len(val_user_hists)}, 测试样本={len(test_user_hists)}\")\n    # 创建数据加载器\n    train_dataset = UserItemDataset(train_user_hists, train_target_items, train_hist_lens)\n    val_dataset = UserItemDataset(val_user_hists, val_target_items, val_hist_lens)\n    test_dataset = UserItemDataset(test_user_hists, test_target_items, test_hist_lens)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n    # 初始化模型\n    model = MIND(num_items, embedding_dim, k_max, pow_p, dynamic_k).to(device)\n    # 定义优化器和学习率调度器\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n    # 训练模型\n    print(\"开始训练模型...\")\n    train_losses, val_losses, metrics_history, best_metrics = train_model(\n        model, train_loader, val_loader, optimizer, scheduler, device, epochs)\n    # 绘制损失曲线\n    plot_losses(train_losses, val_losses, save_path='mind_loss_curve.png')\n    # 绘制指标曲线\n    plot_metrics(metrics_history, epochs, save_path='mind_metrics_curve.png')\n    # 加载最佳模型并在测试集上评估\n    model.load_state_dict(torch.load('best_mind_model.pth'))\n    print(\"评估测试集性能...\")\n    test_metrics = evaluate_model(model, test_loader, device)\n    # 绘制不同K值的最终指标对比\n    plot_final_metrics(test_metrics, save_path='mind_final_metrics.png')\n    print(\"训练和评估完成!\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T13:56:36.233652Z","iopub.execute_input":"2025-07-08T13:56:36.234230Z","execution_failed":"2025-07-08T14:05:59.319Z"}},"outputs":[{"name":"stdout","text":"下载并处理MovieLens-1M数据集...\n读取和处理数据...\n数据集信息: 物品数量=3953, 训练样本=6034, 验证样本=6034, 测试样本=6034\n开始训练模型...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/1000, Train Loss: 6.4151, Val Loss: 6.8691, LR: 0.010000\nEvaluating model at epoch 10...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 24/24 [00:01<00:00, 12.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"HR@10: 0.0308, NDCG@10: 0.0161\nHR@20: 0.0471, NDCG@20: 0.0201\nHR@50: 0.0819, NDCG@50: 0.0270\nEpoch 20/1000, Train Loss: 5.8947, Val Loss: 6.6502, LR: 0.010000\nEvaluating model at epoch 20...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 24/24 [00:01<00:00, 12.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"HR@10: 0.0331, NDCG@10: 0.0171\nHR@20: 0.0522, NDCG@20: 0.0219\nHR@50: 0.0965, NDCG@50: 0.0307\nEpoch 30/1000, Train Loss: 5.6222, Val Loss: 6.5464, LR: 0.010000\nEvaluating model at epoch 30...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 24/24 [00:01<00:00, 12.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"HR@10: 0.0360, NDCG@10: 0.0183\nHR@20: 0.0568, NDCG@20: 0.0235\nHR@50: 0.1064, NDCG@50: 0.0332\nEpoch 40/1000, Train Loss: 5.4068, Val Loss: 6.5117, LR: 0.010000\nEvaluating model at epoch 40...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 24/24 [00:01<00:00, 12.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"HR@10: 0.0370, NDCG@10: 0.0189\nHR@20: 0.0588, NDCG@20: 0.0244\nHR@50: 0.1079, NDCG@50: 0.0340\nEpoch 50/1000, Train Loss: 5.2138, Val Loss: 6.4642, LR: 0.010000\nEvaluating model at epoch 50...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 24/24 [00:01<00:00, 12.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"HR@10: 0.0318, NDCG@10: 0.0166\nHR@20: 0.0530, NDCG@20: 0.0219\nHR@50: 0.0968, NDCG@50: 0.0305\n","output_type":"stream"}],"execution_count":null}]}